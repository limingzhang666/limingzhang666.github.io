---
title: 深入理解jvm-16-Java内存模型与线程
copyright: true
related_posts: true
date: 2021-01-31 13:39:44
tags: java内存模型与线程
categories: jvm

---

# Java内存模型与线程

衡量一个服务性能的高低好坏，**每秒事务处理数（Transactions Per Second，TPS**）是重要的指标之一，它代表着一秒内服务端平均能响应的请求总数，而TPS值与程序的并发能力又是有非常密切的关系。对于计算量相同的任务，程序线程并发协调得有条不紊，效率自然就会很高；反之 线程之间频繁争用数据，互相阻塞甚至死锁，将会大大降低程序得并发能力。



## 硬件的效率与一致性

我们先花费一点时间去了解一下物理计算机中的并发问题。**物理机遇到的并发问题与虚拟机中的情况有很多相似之处**，物理机对并发的处理方案对虚拟
机的实现也有相当大的参考意义。

物理机：

由于计算机的存储设备与处理器的运算速度有着几个数量级的差距，所以现代计算机系统都不得不加入一层或多层读写速度尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲： 

-  将运算需要使用的数据复制到缓存中，让运算能快速的进行，
- 当运算结束后，在将缓存中的数据同步到内存之中，这样处理器就无须等待缓慢的内存读写了。

基于高速缓存的存储交互很好地解决了处理器和内存速度之间的矛盾，但是也为计算机系统带来了更高的复杂度，它引入了一个新的问题：  **缓存一致性（Cache  Coherence）** 。在多路处理器系统中，每个处理器都有自己的高速缓存，而他们又共享同一主内存（Main Memory），这种系统被称为 **共享内存多核系统（Shared Memory Multi-processors system）**，如下图所示。当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致。如果真的发生这种情况，那同步回到主内存时该以谁的缓存数据为准呢？为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有MSI、MESI（Illinois Protocol）、MOSI、Synapse、Firefly及Dragon Protocol等。

从本章开始，我们将会频繁见到“**内存模型**”一词，它可以理解为在特定的操作协议下，对特定的内存或高速缓存进行读写访问的过程抽象。

- 不同架构的物理机器可以拥有不一样的内存模型，
- 而Java虚拟机也有自己的内存模型，并且这里介绍的**内存访问操作以及硬件的缓存访问操作具有高度的可类比性。**

![](/uploads/jvm/14memoryModel/cpu-memory-interaction.png)

除了增加**高速缓存**之外，为了使处理器内部的运算单元能尽量被充分利用，处理器可能会对输入代码进行**乱序执行（Out-Of-Order Execution）优化**，处理器会在计算之后将乱序执行的结果重组，保证该结果与顺序执行的结果是一致的，但**并不保证程序中各个语句计算的先后顺序与输入代码中的顺序一致**，因此如果存在一个计算任务依赖另外一个计算任务的中间结果，那么其顺序性并不能靠代码的先后顺序来保证。与处理器的乱序执行优化类似，Java虚拟机的即时编译器中也有   **指令重排序（Instruction Reorder）优化**。

## Java内存模型

《Java虚拟机规范》中曾试图定义一种**“Java内存模型”（Java Memory Model，JMM）**来屏蔽各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。

定义Java内存模型并非一件容易的事情，这个模型必须定义得足够严谨，才能让Java的并发内存访问操作不会产生歧义；但是也必须定义得足够宽松，使得虚拟机的实现能有足够的自由空间去利用硬件的各种特性（寄存器、高速缓存和指令集中某些特有的指令）来获取更好的执行速度。经过长时间的验证和修补，

直至JDK 5（实现了JSR-133[3]）发布后，Java内存模型才终于成熟、完善起来了。



### 主内存与工作内存

- Java内存模型的主要目的是定义程序中各种变量的访问规则，即关注在虚拟机中把变量值存储到内存和从内存中取出变量值这样的底层细节
- 此处的变量（Variables）与Java编程中所说的变量有所区别，它包括了**实例字段、静态字段和构成数组对象的元素**，但是**不包括局部变量与方法参数**，因为后者是线程私有的，不会被共享，自然就不会存在竞争问题

- Java内存模型规定了所有的变量都存储在主内存（Main Memory）中（此处的主内存与介绍物理硬件时提到的主内存名字一样，两者也可以类比，但物理上它仅是虚拟机内存的一部分）
- 每条线程还有自己的工作内存（Working Memory，可与前面讲的处理器高速缓存类比），线程的工作内存中保存了被该线程使用的变量的主内存副本[2]，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的数据
- 不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成，线程、主内存、工作内存三者的交互关系如图12-2所示，注意与图12-1进行对比。

![](/uploads/jvm/14memoryModel/thread-memory-interaction.png)

ps： 如果局部变量是一个reference类型，它引用的对象在Java堆中可被各个线程共享，但是reference本身在Java栈的局部变量表中是线程私有的

### 内存间交互操作

关于主内存与工作内存之间具体的交互协议，即一个变量如何从**主内存拷贝到工作内存**、如何从**工作内存同步回主内存**这一类的实现细节，Java内存模型中定义了以下8中操作来完成。Java虚拟机实现时必须保证下面提及的每一种操作都是原子的、不可再分的（对于double和long类型的变量来说，load、store、read和write操作在某些平台上允许有例外）

- lock（锁定）： 作用于 **主内存的变量**，它把一个变量标识为一条线程独占的状态
- unlock(解锁): 作用域主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。
- read（读取）： 作用域主内存的变量，它把一个变量的值从主内存传输到 线程的工作内存中，以便随后的load动作使用
- load（载入）： 作用于 工作内存的变量，它把read操作从主内存中得到的变量值 放入到工作内存的变量副本中。
- use（使用）： 作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。
- assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接受的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作
- store（存储）： 作用于工作内存的变量，它把工作内存中一个变量的值 传送到主内存中，以便随后的write操作使用
- write(写入)： 作用于主内存的变量，它把store 操作从工作内存中得到的变量的值放入主内存的变量中。



如果要把一个变量从主内存拷贝到工作内存，那就要按顺序执行read和load操作，如果要把变量从工作内存同步回主内存，就要按顺序执行store和write操作。

注意，Java内存模型只要求上述两个操作必须按顺序执行，但不要求是连续执行。也就是说read与load之间、store与write之间是可插入其他指令
的，如对主内存中的变量a、b进行访问时，一种可能出现的顺序是read a、read b、load b、load a。除此之外，Java内存模型还规定了在执行上述8种基本操作时必须满足如下规则：

- 不允许read和load、store和write操作之一单独出现，即不允许一个变量从主内存读取了但工作内存不接受，或者工作内存发起回写了但主内存不接受的情况出现。
- 不允许一个线程丢弃它最近的assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。
- 不允许一个线程无原因地（没有发生过任何assign操作）把数据从线程的工作内存同步回主内存中。
- 一个新的变量只能在主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量，换句话说就是对一个变量实施use、store操作之前，必须先执行assign和load操作。
- 一个变量在同一个时刻只允许一条线程对其进行lock操作，但 **lock操作可以被同一条线程重复执行多次**，多次执行lock后，**只有执行相同次数的unlock操作，变量才会被解锁。**
- 如果对一个变量执行lock操作，那将会**清空工作内存中此变量的值**，在执行引擎使用这个变量前，需要**重新执行load或assign操作以初始化变量的值**。
- 如果一个变量事先没有被lock操作锁定，那就不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定的变量
- 对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、write操作）。

### 对于volatile型变量的特殊规则

关键字 volatile可以说时java虚拟机提供的最轻量级的同步机制，了解volatile 变量的语义对后面理解多线程操作的其他特性很有意义。

当一个变量被定义为 volatile 之后，它将具备两项特性： 

- 第一项是 保证此变量对所有线程的可见性，这里的“可见性”是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。而普通变量并不能做到这一点，普通变量的值在线程间传递时需要 都需要通过主内存来完成。 比如： 线程A修改了一个普通变量的值，然后向主内存进行回写， 另外一条线程B在线程A回写完成了之后 再对主内存进行读取操作，新变量值才会对线程B可见。
- 关于volatile变量的可见性，经常会被开发人员误解，他们会误以为这句话的描述时正确的： “**volatile变量对所有线程是立即可见的，对volatile变量所有的写操作都能立刻反映到其他线程之中**。换句话说，volatile变量在各个线程中是一致的，所以基于volatile变量的运算在并发下是线程安全的”  这句话的**论据部分并没有错，**但是由其论据并不能得出“基于volatile变量的运算在并发下是线程安全的”这样的结论。
- volatile变量在各个线程的工作内存中是不存在一致性问题的（从物理存储的角度看，各个线程的工作内存中volatile变量也可以存在不一致的情况，但**由于每次使用之前都要先刷新，执行引擎看不到不一致的情况，因此可以认为不存在一致性问题**），但是**Java里面的运算操作符并非原子操作**，这导致volatile变量的运算在并发下一样是不安全的，我们可以通过一段简单的演示来说明原因，请看代码清单12-1中演示的例子。

```java
/**
 * volatile变量自增运算测试
 *
 * @author zzm
 */
public class VolatileTest {

    public static volatile int race = 0;

    public static void increase() {
       
        race++;
    }

    private static final int THREADS_COUNT = 20;

    public static void main(String[] args) {
        Thread[] threads = new Thread[THREADS_COUNT];
        for (int i = 0; i < THREADS_COUNT; i++) {
            threads[i] = new Thread(new Runnable() {
                @Override
                public void run() {
                    for (int i = 0; i < 10000; i++) {
                        increase();
                    }
                }
            });
            threads[i].start();
        }

        // 等待所有累加线程都结束
        while (Thread.activeCount() > 2)
            Thread.yield();

        System.out.println(race);
    }
}
```

#### 结果分析:

这段代码发起了20个线程，每个线程对race变量进行10000次自增操作，如果这段代码能够正确并发的话，最后输出的结果应该是200000。读者运行完这段代码之后，并不会获得期望的结果，而且会发现每次运行程序，输出的结果都不一样，都是一个小于200000的数字。这是为什么呢？



问题就出在自增运算“race++”之中，我们用Javap反编译这段代码后会得到代码清单12-2所示，发现只有一行代码的increase()方法在Class文件中是由4条字节码指令构成（return指令不是由race++产生的，这条指令可以不计算），从字节码层面上已经很容易分析出并发失败的原因了：当getstatic指令把race的值取到操作栈顶时，volatile关键字保证了race的值在此时是正确的，但是在执行iconst_1、iadd这些指令的时候，其他线程可能已经把race的值改变了，而操作栈顶的值就变成了过期的数据，所以putstatic指令执行后就可能把较小的race值同步回主内存之中。

代码清单12-2　VolatileTest的字节码

```java
public static void increase();
    Code:
        Stack=2, Locals=0, Args_size=0
        0: getstatic		 #13; //Field race:I
        3: iconst_1
        4: iadd
        5: putstatic		 #13; //Field race:I
        8: return
        LineNumberTable:
        line 14: 0
        line 15: 8
```

实事求是地说，使用字节码来分析并发问题仍然是不严谨的，因为即使编译出来只有一条字节码指令，也并不意味执行这条指令就是一个原子操作。一条字节码指令在解释执行时，解释器要运行许多行代码才能实现它的语义。如果是编译执行，一条字节码指令也可能转化成若干条本地机器码指令。

此处使用-XX：+PrintAssembly参数输出反汇编来分析才会更加严谨一些，

**由于volatile 变量只能保证可见性，在不符合一下两条规则的运算场景中**，我们仍然要通过加锁（使用synchronized、java.util.concurrent中的锁 或者原子类）来保证原子性：

- 运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值
- 变量不需要与其他的状态变量共同参与不变约束

而在像代码清单12-3所示的这类场景中就很适合使用volatile变量来控制并发，当shutdown()方法被调用时，能保证所有线程中执行的doWork()方法都立即停下来。

```java
volatile boolean shutdownRequested;
public void shutdown() {
	shutdownRequested = true;
}
public void doWork() {
    while (!shutdownRequested) {
    // 代码的业务逻辑
    }
}
```

使用volatile 变量的第二个语义是  **禁止指令重排序优化**，普通的变量仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序 与程序代码中的执行顺序一致。因为在同一个线程的方法执行过程中无法感知到这点，这就是Java内存模型中描述的所谓“**线程内表现为串行的语义”（Within-Thread As-If-Serial Semantics）”**





代码清单12-4　指令重排序

```java
Map configOptions;
char[] configText;
// 此变量必须定义为volatile
volatile boolean initialized = false;
// 假设以下代码在线程A中执行
// 模拟读取配置信息，当读取完成后
// 将initialized设置为true,通知其他线程配置可用
configOptions = new HashMap();
configText = readConfigFile(fileName);
processConfigOptions(configText, configOptions);
initialized = true;
// 假设以下代码在线程B中执行
// 等待initialized为true，代表线程A已经把配置信息初始化完成
while (!initialized) {
	sleep();
}/
/ 使用线程A中初始化好的配置信息
doSomethingWithConfig();
```

上面的代码时一段伪代码，其中描述的是 开发中常见的配置读取过程。只是我们在处理配置文件的时候一般都不会并发，所以没有察觉到这会有问题。

如果定义initialized 变量时没有使用volatile修饰，就可能会由于指令重排序的优化，导致位于线程A中最后一条代码 initialized=true 被提前执行。这样在线程B中使用配置信息的代码就可能出现错误，而 volatile 关键字则可以避免此类情况的发生 。

指令重排序是并发编程中最容易导致开发人员产生疑惑的地方之一，除了上面伪代码的例子之外，再举一个可以实际操作运行的例子来分析volatile关键字是如何禁止指令重排序优化的。代码清单12-5所示是一段标准的双锁检测（Double Check Lock，DCL）单例[3]代码，可以观察加入volatile和未加入volatile关键字时所生成的汇编代码的差别。
代码清单12-5　DCL单例模式

```java
public class Singleton {
    private volatile static Singleton instance;
    public static Singleton getInstance() {
        if (instance == null) {
        synchronized (Singleton.class) {
            if (instance == null) {
                instance = new Singleton();
        	}
          }
        }
        return instance;
    }
    public static void main(String[] args) {
    	Singleton.getInstance();
    }
}
```

编译后，这段代码对instance变量赋值的部分如代码清单12-6所示。
代码清单12-6　对instance变量赋值

![image-20210131213832956](/uploads/jvm/14memoryModel/MemoryBarries.png)

通过对比发现，关键变化在于有volatile修饰的变量，赋值后（前面mov%eax，0x150(%esi)这句便是赋值操作）多执行了一个“lock addl$0x0，(%esp)”操作，这个操作的作用相当于一个**内存屏障（Memory Barrier或Memory Fence，指重排序时不能把后面的指令重排序到内存屏障之前的位置**，注意不要与第3章中介绍的垃圾收集器用于捕获变量访问的内存屏障互相混淆），只有一个处理器访问内存时，并不需要内存屏障；但如果有两个或更多处理器访问同一块内存，且其中有一个在观测另一个，就需要内存屏障来保证一致性了。

#### volatile性能问题

- 在某些情况下，volatile的同步机制的性能确实要优于锁（使用synchronized关键字或java.util.concurrent包里面的锁），
- 但是由于虚拟机对锁实行的许多消除和优化，使得我们很难确切地说volatile就会比synchronized快上多少。
- volatile变量读操作的性能消耗与普通变量几乎没有什么差别，但是写操作则可能会慢上一些，因为它需要在本地代码中插入许多内存屏障指令来保证处理器不发生乱序执行
- 不过即便如此，大多数场景下volatile的总开销仍然要比锁来得更低
- 我们在volatile与锁中选择的唯一判断依据**仅仅是volatile的语义能否满足使用场景的需求。**



#### Java内存模型中对volatile变量定义的特殊规则

假定T表示一个线程，V和W分别表示两个volatile型变量，那么在进行read、load、use、assign、store和write操作时需要满足如下规则：

1. 只有当线程T对变量V执行的前一个动作是load的时候，线程T才能对变量V执行use动作；并且，只有当线程T对变量V执行的后一个动作是use的时候，线程T才能对变量V执行load动作。线程T对变量V的use动作可以认为是和线程T对变量V的load、read动作相关联的，必须连续且一起出现。  （**这条规则要求在工作内存中，每次使用V前都必须先从主内存刷新最新的值，用于保证能看见其他线程对变量V所做的修改**）
2. 只有当线程T对变量V执行的前一个动作是assign的时候，线程T才能对变量V执行store动作；并且，只有当线程T对变量V执行的后一个动作是store的时候，线程T才能对变量V执行assign动作。线程T对变量V的assign动作可以认为是和线程T对变量V的store、write动作相关联的，必须连续且一起出现。（**这条规则要求在工作内存中，每次修改V后都必须立刻同步回主内存中，用于保证其他线程可以**
   **看到自己对变量V所做的修改。**）
3. 假定动作A是线程T对变量V实施的use或assign动作，假定动作F是和动作A相关联的load或store动作，假定动作P是和动作F相应的对变量V的read或write动作；与此类似，假定动作B是线程T对变量W实施的use或assign动作，假定动作G是和动作B相关联的load或store动作，假定动作Q是和动作G相应的
   对变量W的read或write动作。如果A先于B，那么P先于Q。(**这条规则要求volatile修饰的变量不会被指令重排序优化，从而保证代码的执行顺序与程序的顺序**
   **相同。**)

#### 原子性、可见性与有序性

Java内存模型是围绕在并发过程中如何处理原子性、可见性和有序性着三个特征来建立的。

1. 原子性

- 由Java内存模型来直接保证的原子性变量操作包括 read、load、assign、use、store和write这六个，我们大致可以认为，基本数据类型的访问、读写 都具备原子性的（例外就是long和double 的非原子性协定，）

- 如果应用场景需要一个更大范围的原子性保证，Java内存模型 还提供了lock 和 unlock操作来满足这种需求，尽管虚拟机 未把lock 和unlock 操作直接开放给用户使用，但是却提供了更高层次的字节码指令 monitor-enter 和 monitor-exit来隐式地使用这两个操作。 这两个字节码指令映射到Java代码中就是同步块-synchronized 关键字，因此在synchronized 块之间地操作也具备原子性。

2. 可见性

可见性就指 ：当一个线程修改了共享变量地值的时候，其他线程能够立即得知这个修改。之前地volatile 变量就是这样的。

- Java内存模型是通过在变量修改后将新值同步回主内存， 在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式来实现可见性的，无论是普通变量还是volatile变量都是如此。普通变量与volatile变量的区别是，volatile的特殊规则保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新。因此我们可以说volatile保证了多线程操作时变量的可见性，而普通变量则不能保证这一点。

- 除了volatile之外，Java还有两个关键字能实现可见性，它们是synchronized和final。同步块的可见性是由“对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、write操作）”这条规则获得的。
- 而final关键字的可见性是指：被final修饰的字段在构造器中一旦被初始化完成，并且构造器没有把“this”的引用传递出去（this引用逃逸是一件很危险的事情，其他线程有可能通过这个引用访问到“初始化了一半”的对象），那么在其他线程中就能看见final字段的值。

3. 有序性

- Java程序中天然的有序性可以总结为1句话： **如果在本线程内观察，所有的操作都是有序的**； **如果在一个线程中观察 另一个线程，所有的操作都是无序的**。

- 前半句是指“**线程内似表现为串行的语义”（Within-Thread As-If-SerialSemantics）**，后半句是指“**指令重排序”现象和“工作内存与主内存同步延迟**”现象。
- Java语言提供了volatile和synchronized两个关键字来保证线程之间操作的有序性，volatile关键字本身就包含了禁止指令重排序的语义，而synchronized则是由“一个变量在同一个时刻只允许一条线程对其进行lock操作”这条规则获得的，这个规则决定了持有同一个锁的两个同步块只能串行地进入。

#### 先行发生原则

它是判断数据是否存在竞争，线程是否安全的非常有用的手段。依赖这个原则，我们可以通过几条简单规则一揽子解决并发环境下两个操作之间是否可能存在冲突的所有问题，而不需要陷入Java内存模型苦涩难懂的定义之中。

先行发生是 Java内存模型中定义的两项操作之间的偏序关系，比如操作A 先行发生于操作B，其实就是说在发生操作B之前，操作A产生的影响 能被操作B观察到，影响包括修改了内存中共享变量的值、发送了消息、调用了方法等。

代码清单12-8　先行发生原则示例1

```bash
// 以下操作在线程A中执行
i = 1;
// 以下操作在线程B中执行
j = i;
// 以下操作在线程C中执行
i = 2;
```



假设线程A中的操作“i=1”先行发生于线程B的操作“j=i”，那我们就可以确定在线程B的操作执行后，变量j的值一定是等于1，得出这个结论的依据有两个：

- 一是根据先行发生原则，“i=1”的结果可以被观察到
- 二是线程C还没登场，线程A操作结束之后没有其他线程会修改变量i的值

现在再来考虑线程C，我们依然保持线程A和B之间的先行发生关系，而C出现在线程A和B的操作之间，但是C与B没有先行发生关系，那j的值会是多少呢？

答案是不确定！1和2都有可能，因为线程C对变量i的影响可能会被线程B观察到，也可能不会，这时候**线程B就存在读取到过期数据的风险**，不具备多线程安全性。

下面是Java内存模型下一些“天然的”先行发生关系，这些先行发生关系无须任何同步器协助就已经存在，可以在编码中直接使用。如果两个操作之间的关系不在此列，并且无法从下列规则推导出来，则它们就没有顺序性保障，虚拟机可以对它们随意地进行重排序。

- **程序次序规则（Program Order Rule）**：在一个线程内，按照控制流顺序，书写在前面的操作先行发生于书写在后面的操作。注意，这里说的是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。
- **管程锁定规则（Monitor Lock Rule）**：一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是“同一个锁”，而“后面”是指时间上的先后。
- **volatile变量规则（Volatile Variable Rule）**：对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的“后面”同样是指时间上的先后。
- **线程启动规则（Thread Start Rule）**：Thread对象的start()方法先行发生于此线程的每一个动作。
- **线程终止规则（Thread Termination Rule）**：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread::join()方法是否结束、Thread::isAlive()的返回值等手段检测线程是否已经终止执行。
- **线程中断规则（Thread Interruption Rule）**：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread::interrupted()方法检测到是否有中断发生
- **对象终结规则（Finalizer Rule）**：一个对象的初始化完成（构造函数执行结束）先行发生于它的finalize()方法的开始。
- **传递性（Transitivity）**：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。

Java语言无须任何同步手段保障就能成立的先行发生规则有且只有上面这些，下面演示一下如何使用这些规则去判定操作间是否具备顺序性，对于读写共享变量的操作来说，就是线程是否安全。读者还可以从下面这个例子中感受一下“时间上的先后顺序”与“先行发生”之间有什么不同。演示例子如
代码清单12-9所示。

```java
private int value = 0;
pubilc void setValue(int value){
	this.value = value;
}
public int getValue(){
	return value;
}
```



代码清单12-9中显示的是一组再普通不过的getter/setter方法，假设存在线程A和B，线程A先（时间上的先后）调用了setValue(1)，然后线程B调用了同一个对象的getValue()，那么线程B收到的返回值是什么？
我们依次分析一下先行发生原则中的各项规则。

- 由于两个方法分别由线程A和B调用，不在一个线程中，所以程序次序规则在这里不适用；

- 由于没有同步块，自然就不会发生lock和unlock操作，所以管程锁定规则不适用；

- 由于value变量没有被volatile关键字修饰，所以volatile变量规则不适用；

- 后面的线程启动、终止、中断规则和对象终结规则也和这里完全没有关系。

- 因为没有一个适用的先行发生规则，所以最后一条传递性也无从谈起，

- 因此我们可以判定，尽管线程A在操作时间上先于线程B，但是无法确定线程B中getValue()方法的返回结果，换句话说，这里面的操作不是线程安全的。

  那怎么修复这个问题呢？我们至少有两种比较简单的方案可以选择：

  - 要么把getter/setter方法都定义为synchronized方法，这样就可以套用管程锁定规则；
  - 要么把value定义为volatile变量，由于setter方法对value的修改不依赖value的原值，满足volatile关键字使用场景，这样就可以套用volatile变量规则来
    实现先行发生关系。



## 线程的实现

### Java线程的实现

Java线程如何实现并不受Java虚拟机规范的约束，这是一个与具体虚拟机相关的话题。

- Java线程在早期的Classic虚拟机上（JDK 1.2以前），是基于一种被称为“绿色线程”（Green Threads）的用户线程实现的，
- 但从JDK 1.3起，“主流”平台上的“主流”商用Java虚拟机的线程模型普遍都被替换为基于操作系统原生线程模型来实现，即采用1：1的线程模型。

以HotSpot为例，它的每一个Java线程都是直接映射到一个**操作系统原生线程来实现的**，而且中间没有额外的间接结构，所以**HotSpot自己是不会去干涉线程调度的**（可以设置线程优先级给操作系统提供调度建议），全权交给底下的操作系统去处理，所以何时冻结或唤醒线程、该给线程分配多少处理器执行时间、该把线程安排给哪个处理器核心去执行等，都是**由操作系统完成的**，也都是由操作系统全权决定的。

### Java线程调度

线程调度是指系统为线程分配处理器使用权的过程，调度主要方式有两种，分别是**协同式（Cooperative Threads-Scheduling）线程调度和抢占式（Preemptive Threads-Scheduling）线程调度。**

- 如果使用协同式调度的多线程系统，线程的执行时间由线程本身来控制，线程把自己的工作执行完了之后，要主动通知系统切换到另外一个线程上去。协同式多线程的最大好处是实现简单，而且由于线程要把自己的事情干完后才会进行线程切换，切换操作对线程自己是可知的，所以一般没有什么线程同步的问题.

  它的坏处也很明显：线程执行时间不可控制，甚至如果一个线程的代码编写有问题，一直不告知系统进行线程切换，那么程序就会一直阻塞在
  那里。

- 如果使用抢占式调度的多线程系统，那么每个线程将由系统来分配执行时间，线程的切换不由线程本身来决定。譬如在Java中，有Thread::yield()方法可以主动让出执行时间，但是如果想要主动获取执行时间，线程本身是没有什么办法的。在这种实现线程调度的方式下，线程的执行时间是系统可控的，也不会有一个线程导致整个进程甚至整个系统阻塞的问题。Java使用的线程调度方式就是抢占式调度.

- 虽然说Java线程调度是系统自动完成的，但是我们仍然可以“建议”操作系统给某些线程多分配一点执行时间，另外的一些线程则可以少分配一点——这项操作是通过设置线程优先级来完成的。Java语言一共设置了10个级别的线程优先级（Thread.MIN_PRIORITY至Thread.MAX_PRIORITY）。在两个线程同时处于Ready状态时，优先级越高的线程越容易被系统选择执行。

- 不过，**线程优先级并不是一项稳定的调节手段**，很显然因为主流虚拟机上的Java线程是被映射到系统的原生线程上来实现的，所以线程调度最终还是由操作系统说了算

### 状态转换

Java语言定义了6种线程状态，在任意一个时间点中，一个线程只能有且只有其中的一种状态，并且可以通过特定的方法在不同状态之间转换。这6种状态分别是：

- 新建（New）：创建后尚未启动的线程处于这种状态。
- 运行（Runnable）：包括操作系统线程状态中的Running和Ready，也就是处于此状态的线程有可能正在执行，也有可能正在等待着操作系统为它分配执行时间。
- 无限期等待（Waiting）：处于这种状态的线程不会被分配处理器执行时间，它们要等待被其他线程显式唤醒。以下方法会让线程陷入无限期的等待状态：

  - 没有设置Timeout参数的Object::wait()方法；

  - 没有设置Timeout参数的Thread::join()方法；

  - LockSupport::park()方法。
- 限期等待（Timed Waiting）：处于这种状态的线程也不会被分配处理器执行时间，不过无须等待被其他线程显式唤醒，在一定时间之后它们会由系统自动唤醒。以下方法会让线程进入限期等待状态：

  - Thread::sleep()方法；
  - 设置了Timeout参数的Object::wait()方法；
  - 设置了Timeout参数的Thread::join()方法；
  - LockSupport::parkNanos()方法；
  - LockSupport::parkUntil()方法。
- 阻塞（Blocked）：线程被阻塞了，“阻塞状态”与“等待状态”的区别是“阻塞状态”在等待着获取到
一个排它锁，这个事件将在另外一个线程放弃这个锁的时候发生；而“等待状态”则是在等待一段时
间，或者唤醒动作的发生。在程序等待进入同步区域的时候，线程将进入这种状态。
- 结束（Terminated）：已终止线程的线程状态，线程已经结束执行。

上述6种状态在遇到特定事件发生的时候将会互相转换，它们的转换关系如图12-6所示。

![](/uploads/jvm/14memoryModel/thread-status-trans.png)

## Java与协程

### 内核线程的局限

可以通过一个具体场景来解释目前Java线程面临的困境。今天对Web应用的服务要求，不论是在请求数量上还是在复杂度上，与十多年前相比已不可同日而语，这一方面是源于业务量的增长，另一方面来自于为了应对业务复杂化而不断进行的服务细分。现代B/S系统中一次对外部业务请求的响应，往往需要分布在不同机器上的大量服务共同协作来实现，这种服务细分的架构在减少单个服务复杂度、增加复用性的同时，也不可避免地增加了服务的数量，缩短了留给每个服务的响应时间。这要求每一个服务都必须在极短的时间内完成计算，这样组合多个服务的总耗时才不会太长；也要求每一个服务提供者都要能同时处理数量更庞大的请求，这样才不会出现请求由于某个服务被阻塞而出现等待。



Java目前的并发编程机制就与上述架构趋势产生了一些矛盾，1：1的内核线程模型是如今Java虚拟机线程实现的主流选择，但是这种映射到操作系统上的线程天然的缺陷是切换、调度成本高昂，系统能容纳的线程数量也很有限。以前处理一个请求可以允许花费很长时间在单体应用中，具有这种线程切换的成本也是无伤大雅的，但现在在每个请求本身的执行时间变得很短、数量变得很多的前提下，用户线程切换的开销甚至可能会接近用于计算本身的开销，这就会造成严重的浪费。

传统的Java Web服务器的线程池的容量通常在几十个到两百之间，当程序员把数以百万计的请求往线程池里面灌时，系统即使能处理得过来，但其中的切换损耗也是相当可观的。现实的需求在迫使Java去研究新的解决方案，同大家又开始怀念以前绿色线程的种种好处

### 协程的复苏

Q&A : 为什么内核线程调度切换起来成本就要更高？

内核线程的调度成本主要来自于用户态与核心态之间的状态转换，而这两种状态转换的开销主要来自于响应中断、保护和恢复执行现场的成本。

假设发生了这样一次线程切换：**线程A -> 系统中断 -> 线程B**

处理器要去执行线程A的程序代码时，并不是仅有代码程序就能跑得起来，程序是数据与代码的组合体，代码执行时还必须要有上下文数据的支撑。而这里说的“上下文”，

- 以程序员的角度来看，是方法调用过程中的各种局部的变量与资源；
- 以线程的角度来看，是方法的调用栈中存储的各类信息；
- 而以操作系统和硬件的角度来看，则是存储在内存、缓存和寄存器中的一个个具体数值。
- 物理硬件的各种存储设备和寄存器是被操作系统内所有线程共享的资源，当中断发生，从线程A切换到线程B去执行之前，操作系统首先要把线程A的上下文数据妥善保管好，然后把寄存器、内存分页等恢复到线程B挂起时候的状态，这样线程B被重新激活后才能仿佛从来没有被挂起过。这种保护和恢复现场的工作，免不了涉及一系列数据在各种寄存器、缓存中的来回拷贝，当然不可能是一种轻量级的操作。



由于最初多数的用户线程是被设计成协同式调度（Cooperative Scheduling）的，所以它有了一个别名——“协程”（Coroutine）。又由于这时候的协程会
完整地做调用栈的保护、恢复工作，所以今天也被称为“有栈协程”（Stackfull Coroutine），起这样的名字是为了便于跟后来的“无栈协程”（Stackless Coroutine）区分开。无栈协程不是本节的主角，不过还是可以简单提一下它的典型应用，即各种语言中的await、async、yield这类关键字。无栈协程本质上
是一种有限状态机，状态保存在闭包里，自然比有栈协程恢复调用栈要轻量得多，但功能也相对更有限。

- 协程的主要优势是轻量，无论是有栈协程还是无栈协程，都要比传统内核线程要轻量得多

- 协程当然也有它的局限，需要在应用层面实现的内容（调用栈、调度器这些）特别多，这个缺点就不赘述了。除此之外，协程在最初，甚至在今天很多语言和框架中会被设计成协同式调度，这样在语言运行平台或者框架上的调度器就可以做得非常简单
- 具体到Java语言，还会有一些别的限制，譬如HotSpot这样的虚拟机，Java调用栈跟本地调用栈是做在一起的。如果在协程中调用了本地方法，还能否正常切换协程而不影响整个线程？另外，如果协程中遇传统的线程同步措施会怎样？譬如Kotlin提供的协程实现，一旦遭遇synchronize关键字，那挂起来的仍将是整个线程。