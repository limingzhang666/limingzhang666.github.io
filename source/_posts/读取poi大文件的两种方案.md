---
title: 读取poi大文件的两种方案
copyright: true
comments: true
related_posts: true
date: 2021-03-28 15:51:16
tags: 读取大文件
categories: poi
---


## 背景
最近有个业务需求，功能是：要通过excel 装载大量数据并上传至系统，excel的格式是.xlsx,后台需要解析excel的每条数据，进行一系列 有效性以及权限等校验。
验证通过的需要落数据库， 验证不通过的需要 生成一个异常数据的excel，将每条数据的错误原因 备注在 源数据的最后一列



## 方案

其实如果数据量不大的情况下，我们 可以使用简单的poi 将excel 一次性加载至内存中，然后逐条数据一次解析验证 。

可是当 excel 的数据量特别大的时候，就有可能发生OOM的情况，系统直接就卡死了。这是我们不能容忍的 。解决这个问题的方案这边其实有3种：



### 方案1：poi事件模式+分页处理

看poi的文档，其实poi 的api提供了2种 模式，

- 一种就是我们常用的用户模式usermodel，就是将excel的内容一次性全部加载至 内存中，
- 还有一种用的是 事件模式，因为其实将 的excel文件后缀名.xlsx 改为 .zip，打开zip包 就可以知道其实excel的底层数据是以 xml的形式存储的。所以 事件模式就是 使用sax解析excel 。

poi提供一套api去处理 解析过程，这个api对用户不是很友好，有点晦涩难懂，我们可以通过自行封装这一套 api然后  进行分页paging 分批的去读取数据到内存中  如下所示：

```java
demo:
```





### 方案2：流式处理 







### 方案3： 阿里easyExcel